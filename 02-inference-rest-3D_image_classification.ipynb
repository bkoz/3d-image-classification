{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ1rtVkBamp6"
   },
   "source": [
    "# 3D Image Classification from CT Scans\n",
    "\n",
    "**Author:** [Hasib Zunair](https://twitter.com/hasibzunair)<br>\n",
    "**Date created:** 2020/09/23<br>\n",
    "**Last modified:** 2020/09/23<br>\n",
    "**Description:** Train a 3D convolutional neural network to predict presence of pneumonia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYvszHivamqA"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example will show the steps needed to build a 3D convolutional neural network (CNN)\n",
    "to predict the presence of viral pneumonia in computer tomography (CT) scans. 2D CNNs are\n",
    "commonly used to process RGB images (3 channels). A 3D CNN is simply the 3D\n",
    "equivalent: it takes as input a 3D volume or a sequence of 2D frames (e.g. slices in a CT scan),\n",
    "3D CNNs are a powerful model for learning representations for volumetric data.\n",
    "\n",
    "## References\n",
    "\n",
    "- [A survey on Deep Learning Advances on Different 3D DataRepresentations](https://arxiv.org/pdf/1808.01462.pdf)\n",
    "- [VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition](https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf)\n",
    "- [FusionNet: 3D Object Classification Using MultipleData Representations](http://3ddl.cs.princeton.edu/2016/papers/Hegde_Zadeh.pdf)\n",
    "- [Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction](https://arxiv.org/abs/2007.13224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvHzfu1vamqB"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T13:49:32.504210Z",
     "start_time": "2021-05-19T13:49:25.672396Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pip --upgrade -q\n",
    "!pip install nibabel scipy matplotlib tensorflow ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T13:49:32.513194Z",
     "start_time": "2021-05-19T13:49:32.508542Z"
    },
    "id": "sWdNBCoIamqB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T13:49:32.566922Z",
     "start_time": "2021-05-19T13:49:32.516259Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T13:49:32.890130Z",
     "start_time": "2021-05-19T13:49:32.569098Z"
    },
    "id": "Cw_K_rVZdz5n"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Load model from storage.\n",
    "#\n",
    "import requests\n",
    "url = \"https://koz.s3.amazonaws.com/models/3d_image_classification.h5\"\n",
    "model_file = '3d_image_classification.h5'\n",
    "\n",
    "filename = os.path.join(os.getcwd(), model_file)\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "model = keras.models.load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T13:49:32.999647Z",
     "start_time": "2021-05-19T13:49:32.892237Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Load volume data from storage.\n",
    "#\n",
    "url = \"https://koz.s3.amazonaws.com/data/ct-data.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"ct-data.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Unzip data in the newly created directory.\n",
    "with zipfile.ZipFile(\"ct-data.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T13:49:33.005379Z",
     "start_time": "2021-05-19T13:49:33.001730Z"
    },
    "id": "-4oxO95GamqD"
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2vhqRjoamqJ"
   },
   "source": [
    "## Make predictions on a single CT scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed\n",
    "import matplotlib as mpl\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filename):\n",
    "    #\n",
    "    # payload format\n",
    "    # payload = {\"data\": {\"ndarray\": X.tolist()} }\n",
    "    #\n",
    "    \n",
    "    # \n",
    "    # Load the data set for prediction.\n",
    "    #\n",
    "    v = read_nifti_file(filename)\n",
    "\n",
    "    # Local prediction.\n",
    "    prediction = model.predict(np.expand_dims(v, axis=0))[0]\n",
    "    logging.info(f'Local Prediction {filename} = {prediction}')\n",
    "\n",
    "    #\n",
    "    # Prediction via REST.\n",
    "    #\n",
    "    url = 'http://mymodel-mygroup-odh.apps.ocp.a122.sandbox1172.opentlc.com/api/v1.0/predictions'\n",
    "    logging.info(f'Serializing and predicting volume {filename} via REST')\n",
    "    payload = {\"data\": {\"ndarray\": v.tolist()} }\n",
    "    try:\n",
    "        r = requests.post(url, json = payload, timeout = 5)\n",
    "        logging.debug(f'response: {r}')\n",
    "        j = r.json()['data']['ndarray']\n",
    "        logging.info(f'Volume {filename} prediction: {j:.3f}')\n",
    "\n",
    "    except:\n",
    "        logging.info(f'REST endpoint timed out!')\n",
    "        return None\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load a volume so default dimensions are known for interaction widgets.\n",
    "#\n",
    "global global_v\n",
    "study = 0\n",
    "filename = f'./data/volume{study}.nii.gz'\n",
    "global_v = read_nifti_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(slice = global_v.shape[2] / 2, cmap='none'):\n",
    "    return mpl.pyplot.imshow(global_v[:, :, slice], cmap=cmap, vmin=global_v.min(), vmax=global_v.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicer():\n",
    "    global global_v\n",
    "    interact(slice_image, slice = (0, global_v.shape[2] - 1, 1), cmap=['gray', 'bone', 'hot', 'magma', 'gnuplot2', 'pink']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_volume(study = None):\n",
    "    logging.debug(f'set_volume = {study}')\n",
    "    if (study != None):\n",
    "        filename = f'./data/volume{study}.nii.gz'\n",
    "        logging.debug(f'Loading {filename}')\n",
    "        filename = f'./data/volume{study}.nii.gz'\n",
    "        global global_v\n",
    "        global_v = read_nifti_file(filename)\n",
    "        logging.debug(f'Calling slicer with {filename}, mean = {global_v.mean()}')\n",
    "        predict(filename)\n",
    "        slicer()\n",
    "    else:\n",
    "        global_v = None\n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(set_volume, study = [0, 1, 2, 3, 4, 5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3D_image_classification",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
